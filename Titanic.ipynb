{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1> Titanic para Data Science</h1> </center>\n",
    " # <center> <h1>vive o muere </h1> </center>\n",
    "\n",
    "**********  \n",
    "\n",
    "El trabajo consiste en desarrollar un algoritmo con el que podamos predecir si la probabilidad que una persona muera o viva si viajara en el Titanic, o tal vez poder saber si Jack realmente debió morir según los datos del naufragio. Para lograr este objetivo, usaremos un conjunto de datos de sobre la lista de pasajeros del barco para analizar las variables necesarias y poder construir un modelo de machine learning que nos ayudará a validar los supuestos.\n",
    "\n",
    "**Instrucciones: **\n",
    "- Se usará el lenguaje de programación Python 3.\n",
    "- Se usarán las librerías de python: Pandas, MatPlotLib, Numpy, Scikit-learn.\n",
    "\n",
    "**Mediante este ejercicio, aprenderemos: **\n",
    "- Entender y ejecutar Notebooks con Python.\n",
    "- Ser capaz de utilizar funciones de Python y librerías adicionales.\n",
    "- Dataset:\n",
    " - Obtener el dataset y previsualizar la información del dataset.\n",
    " - Representar y analizar la información del dataset.\n",
    "- Crear y entender el concepto de \"*Conjunto de datos de entrenamiento*\" y \"*Conjuntos de datos de test*\"\n",
    "- Crear y entender el concepto de \"*Clasificador*\" para analizar los datos, predecir y obtener conclusiones.\n",
    "- Mejorar la predicción.\n",
    "\n",
    "¡Te animas!\n",
    "\n",
    "leo.gonzlez11@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importa las librerías necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos algunas librerias \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos los datos pasamos el id de pasajero\n",
    "#Utilizamos dos set de datos uno con todos los datos \"train\" y otro donde esta los datos de testeo \"test\"\n",
    "train = pd.read_csv(r'data\\train.csv')\n",
    "test = pd.read_csv(r'data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trian.head(10)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. creamos un diccionario**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utizaremos el set Train, que contiene el dato de si el pasajero sobrevivio o no\n",
    "\n",
    "- passengerId : ID del pasajero abordo\n",
    "\n",
    "- survival : Sí la persona sobrevivió o no el accidente\n",
    "\n",
    "- pclase : Tipo de Ticket, e.g., 1ra, 2da, 3ra\n",
    "\n",
    "- gender : Género del pasajero: Masculino o femenino\n",
    "\n",
    "- name : Título incluído\n",
    "\n",
    "- age : Edad en anos\n",
    "\n",
    "- sibsp : Número de parientes/cónyuges abordo del Titanic\n",
    "\n",
    "- parch : Número de padres/hijos abordo del Titanic\n",
    "\n",
    "- ticket : Número Ticket\n",
    "\n",
    "- fare : Costo pasaje\n",
    "\n",
    "- cabin : Número cabina\n",
    "\n",
    "- embarked : Puerto de embarcación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. verificamos los datos disponibles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R// Podemos observar que el total de filas es de 891, ademas que **Age, Cabin y Embarked** contiene datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algunas descripciones de las variables numericas.\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R// Si observamos la edad de los pasajeros podemos destacar que las personas que viajaban en el barco era bastante joven, la edad máxima era de 80 años y su minino entorno a cero (recién nacidos o lactantes), por otro lado el 75% de los pasajeros no superaba los 38 año de edad y el 50% no sobrepasaba los 28 años.\n",
    "\n",
    "Por otro lado, podemos ver que el ticket más caro tuvo un valor cercano a los USD 512 y el mínimo fue 0, lo que podría explicar que algunos pasajeros no tuvieron que pagar por su pasaje. (jack se dice se lo gano en una apuesta). Por lado la Desv Standar del precio es de u$49 con una media de USD 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Correlaciones***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Revisemos las correlaciones de las variables para ver como se comportan incialmente\n",
    "#Agregamos style para tener una relacion de colorres\n",
    "train.corr().style.background_gradient().set_precision(4)  #background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que a primeras no existe una correlacion relevante entre las variables numericas, sin embargo podemos hacer algunas correciones a los datos para poder tener mejores conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dejamos el df original por si queremos reinicar desde aca \n",
    "#train = pd.read_csv(r'data\\train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Visualizaciones***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['Sex'])['Age'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['Survived'])['Age'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.groupby(['Sex','Survived'])['Age'].agg('describe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Graficando***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.groupby(['Survived','Sex'])['Age'].agg('count').plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['Survived','Pclass'])['Age'].agg('count').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los pasajeros de 3ra clase fueron los que mas perdieron la vida, tambien podemos ver que fueron mas los hombres que murieron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aplicamos funciones***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICOS BARRA APILADOS\n",
    "#Tambien podemos generar una funcion que agrupe\n",
    "def graf_bar (argumento): #creamos una funcion que recibe un nombre de alguna columna puede tener el nombre que \n",
    "    #creamos las variables de acuerdo a la columna base\n",
    "    vive = train[train['Survived']==1][argumento].value_counts()\n",
    "    muere = train[train['Survived']==0][argumento].value_counts()\n",
    "    #Creamos un df con esas variables y las dejamos en el index\n",
    "    df = pd.DataFrame([vive,muere])\n",
    "    df.index = ['vive','muere']\n",
    "    #ahora podemos graficar en barras acumuladas\n",
    "    df.plot(kind='bar', stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graf_bar('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_bar('Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sns.barplot:\n",
    "La función a nivel de figura seaborn.catplot con el argumento kind = \"bar\" o la función a nivel de ejes seaborn.barplot generan gráficos de barras que tienen un comportamiento ligeramente diferente al habitual: normalmente un gráfico de barras muestra el recuento de valores en cada categoría. Aun cuando esta funcionalidad también está contemplada en seaborn, las funciones mencionadas van mucho más allá de un simple recuento: aplican una función que calcula una medida de tendencia central (por defecto es el valor medio) y muestran, aplicando bootstrapping, el intervalo de confianza del 95% para dicha medida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='Sex', y='Fare', data=train) #valore promedio de la barra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.groupby(['Sex'])['Fare'].agg('describe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(y=\"Age\", x=\"Survived\", hue=\"Pclass\", data=train,kind=\"swarm\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(y=\"Age\", x=\"Survived\", hue=\"Sex\", data=train,kind=\"swarm\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=train, x ='Age', y ='Survived', kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una segunda derivada\n",
    "Si notamos existen datos que estan represetados por variables no numericas que pueden ser factores de realcion con los resultados del naufragio, es decir sobre si el pasajero sobrevive o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Limpiando la data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos primero es transformar las variables Sex y Embarked en var categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sabemos que las var Age, Cabin y Embarked contiene valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que Cabin tiene la mayor cantidad de datos nulos, elimar esas filas afectaria notablemente las conclusiones\n",
    "entonces borraremos la columna, es posible evaluar ene l futuro segun la cabina entender la ubicacion y quizas encontrar algo que nos agregue valor en el futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos los datos\n",
    "train = pd.read_csv(r'data\\train.csv')\n",
    "test = pd.read_csv(r'data\\test.csv')\n",
    "\n",
    "#Transformamos algunos datos descriptivos en numero para poder evaluar\n",
    "# exiten varias formar de transformar datos \n",
    "train['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "train['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)\n",
    "\n",
    "#para la data test\n",
    "test['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "test['Embarked'].replace(['Q','S', 'C'],[0,1,2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminaremos las calumnas que no utilizaremos en esta oportunidad\n",
    "train = train.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "test = test.drop(['Name','Ticket','Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #utulizamos el metodo sklearn que nos permite entrenar algunos modelos regresivos, asigna variables de manear aleatoriatrain\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# labelencoder=LabelEncoder()\n",
    "# train['Sex']=labelencoder.fit_transform(train['Sex'].values)\n",
    "# train['Sex'].unique()\n",
    "# #transformamos lo datos a valores para luego interpolar sobre los datos nulos\n",
    "# labelencoder=LabelEncoder()\n",
    "# train['Embarked']=labelencoder.fit_transform(train['Embarked'].astype(str))\n",
    "# train['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ahora podemos revisar los datos nulos para saber que hacemos con ellos\n",
    "#seria interesanta saber por que faltan edades en el data\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cual es la media?\n",
    "train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Remplazamos los datos nulos por la mediana en cada caso\n",
    "train['Age'].fillna(train['Age'].mean(), inplace=True)\n",
    "train['Embarked'].fillna(train['Embarked'].median(), inplace=True)\n",
    "train['Fare'].fillna(train['Fare'].median(), inplace=True)\n",
    "\n",
    "#para la data test\n",
    "test['Age'].fillna(test['Age'].mean(), inplace=True)\n",
    "test['Embarked'].fillna(test['Embarked'].median(), inplace=True)\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora vamos a entrenar el modelo para poder predecir si los pasajeros de ciertas caracteristica debieron morir o no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#revisamos que no existan datos nulos\n",
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos algunas librerias de SKLEARN \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#aca separo en arreglos la inforacion de los sobrevivientes\n",
    "X = np.array(train.drop(['Survived'], axis=1))\n",
    "Y = np.array(train['Survived'])\n",
    "\n",
    "print(X[1])\n",
    "print(Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperamos la data en entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#regresion logistica\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print('Precisión Regresión Logística:')\n",
    "print(logreg.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_id = test['PassengerId']\n",
    "prediccion_logreg = logreg.predict(test.drop('PassengerId', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_logreg = pd.DataFrame({ 'PassengerId' : test_id, 'Survived': prediccion_logreg })\n",
    "print('Predicción Regresión Logística:')\n",
    "print(out_logreg.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportamos los datos en un df para subir a kaggle\n",
    "#out_logreg.to_csv('Resultados_titanic_LG.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAQUINA VECTORES\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print('Precisión Soporte de Vectores:')\n",
    "print(svc.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediccion_svc = svc.predict(train.drop('PassengerId', axis=1))\n",
    "out_svc = pd.DataFrame({ 'PassengerId' : id, 'Survived': prediccion_svc })\n",
    "print('Predicción Soporte de Vectores:')\n",
    "print(out_svc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vecinos mas cercanos\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "print('Precisión Vecinos más Cercanos:')\n",
    "print(knn.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids = train['PassengerId']\n",
    "prediccion_knn = knn.predict(train.('PassengerId', axis=1))\n",
    "out_knn = pd.DataFrame({ 'PassengerId' : id, 'Survived': prediccion_knn })\n",
    "print('Predicción Vecinos más Cercanos:')\n",
    "print(out_knn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
